{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[*]\") \\\n",
    ".config(\"spark.driver.memory\", \"6g\") \\\n",
    ".getOrCreate()\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "25/06/21 07:10:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "! wget https://github.com/erkansirin78/datasets/raw/refs/heads/master/yellow_tripdata_partitioned_by_day/year=2024/month=10/day=11/part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet\n",
    "--2025-06-21 07:14:09--  https://github.com/erkansirin78/datasets/raw/refs/heads/master/yellow_tripdata_partitioned_by_day/year=2024/month=10/day=11/part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet\n",
    "Resolving github.com (github.com)... 140.82.121.3\n",
    "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
    "HTTP request sent, awaiting response... 302 Found\n",
    "Location: https://raw.githubusercontent.com/erkansirin78/datasets/refs/heads/master/yellow_tripdata_partitioned_by_day/year%3D2024/month%3D10/day%3D11/part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet [following]\n",
    "--2025-06-21 07:14:10--  https://raw.githubusercontent.com/erkansirin78/datasets/refs/heads/master/yellow_tripdata_partitioned_by_day/year%3D2024/month%3D10/day%3D11/part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet\n",
    "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
    "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 355218 (347K) [application/octet-stream]\n",
    "Saving to: ‘part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet’\n",
    "\n",
    "part-00135-5bd1507a 100%[===================>] 346.89K  --.-KB/s    in 0.04s   \n",
    "\n",
    "2025-06-21 07:14:10 (9.02 MB/s) - ‘part-00135-5bd1507a-125d-4ec6-8794-3ed02e45a45d.c000.snappy.parquet’ saved [355218/355218]\n",
    "\n",
    "df = spark.read.format(\"parquet\").load(\"file:///taxi\")\n",
    "df.count()\n",
    "128717\n",
    "df.limit(5).toPandas()\n",
    "VendorID\ttpep_pickup_datetime\ttpep_dropoff_datetime\tpassenger_count\ttrip_distance\tRatecodeID\tstore_and_fwd_flag\tPULocationID\tDOLocationID\tpayment_type\tfare_amount\textra\tmta_tax\ttip_amount\ttolls_amount\timprovement_surcharge\ttotal_amount\tcongestion_surcharge\tAirport_fee\n",
    "0\t2\t2024-10-11 20:08:40\t2024-10-11 20:14:29\t1.0\t1.11\t1.0\tN\t237\t162\t2\t7.9\t1.0\t0.5\t0.00\t0.00\t1.0\t12.90\t2.5\t0.00\n",
    "1\t2\t2024-10-11 20:25:42\t2024-10-11 20:35:23\t1.0\t1.95\t1.0\tN\t163\t236\t1\t11.4\t1.0\t0.5\t1.64\t0.00\t1.0\t18.04\t2.5\t0.00\n",
    "2\t2\t2024-10-11 20:38:41\t2024-10-11 20:50:56\t1.0\t1.56\t1.0\tN\t43\t262\t1\t12.8\t1.0\t0.5\t3.56\t0.00\t1.0\t21.36\t2.5\t0.00\n",
    "3\t2\t2024-10-10 20:56:46\t2024-10-11 20:48:01\t2.0\t2.50\t1.0\tN\t161\t158\t1\t20.5\t1.0\t0.5\t0.00\t0.00\t1.0\t25.50\t2.5\t0.00\n",
    "4\t2\t2024-10-10 21:48:05\t2024-10-11 20:53:38\t1.0\t10.59\t1.0\tN\t138\t125\t1\t45.7\t6.0\t0.5\t6.44\t6.94\t1.0\t70.83\t2.5\t1.75\n",
    "df.printSchema()\n",
    "root\n",
    " |-- VendorID: long (nullable = true)\n",
    " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
    " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
    " |-- passenger_count: double (nullable = true)\n",
    " |-- trip_distance: double (nullable = true)\n",
    " |-- RatecodeID: double (nullable = true)\n",
    " |-- store_and_fwd_flag: string (nullable = true)\n",
    " |-- PULocationID: long (nullable = true)\n",
    " |-- DOLocationID: long (nullable = true)\n",
    " |-- payment_type: long (nullable = true)\n",
    " |-- fare_amount: double (nullable = true)\n",
    " |-- extra: double (nullable = true)\n",
    " |-- mta_tax: double (nullable = true)\n",
    " |-- tip_amount: double (nullable = true)\n",
    " |-- tolls_amount: double (nullable = true)\n",
    " |-- improvement_surcharge: double (nullable = true)\n",
    " |-- total_amount: double (nullable = true)\n",
    " |-- congestion_surcharge: double (nullable = true)\n",
    " |-- Airport_fee: double (nullable = true)\n",
    "\n",
    "TripID\n",
    "PickupDateTimeID\n",
    "DropOffDateTimeID\n",
    "PULocationID\n",
    "DOLocationID\n",
    "RateCodeID\n",
    "PaymentTypeID\n",
    "PassengerCount\n",
    "TripDistance\n",
    "FareAmount\n",
    "TipAmount\n",
    "TollsAmount\n",
    "AirportAmount\n",
    "TotalAmount\n",
    "Extra\n",
    "MTATax\n",
    "CongestionSurcharge\n",
    "Transform timestamps\n",
    "df2 = df.withColumn(\"PickupDateTimeID\",  F.date_format(\"tpep_pickup_datetime\", \"yyyyMMddHHmm\").cast(\"long\")) \\\n",
    ".withColumn(\"DropOffDateTimeID\",  F.date_format(\"tpep_dropoff_datetime\", \"yyyyMMddHHmm\").cast(\"long\"))\n",
    "df2.columns\n",
    "['VendorID',\n",
    " 'tpep_pickup_datetime',\n",
    " 'tpep_dropoff_datetime',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'RatecodeID',\n",
    " 'store_and_fwd_flag',\n",
    " 'PULocationID',\n",
    " 'DOLocationID',\n",
    " 'payment_type',\n",
    " 'fare_amount',\n",
    " 'extra',\n",
    " 'mta_tax',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'total_amount',\n",
    " 'congestion_surcharge',\n",
    " 'Airport_fee',\n",
    " 'PickupDateTimeID',\n",
    " 'DropOffDateTimeID']\n",
    "df3 = df2.select(\n",
    "    F.monotonically_increasing_id().alias(\"TripID\"),\n",
    "    F.col(\"PickupDateTimeID\"),\n",
    "    F.col(\"DropOffDateTimeID\"),\n",
    "    F.col(\"PULocationID\"),\n",
    "    F.col(\"DOLocationID\"),\n",
    "    F.col(\"RatecodeID\").alias(\"RateCodeID\"),\n",
    "    F.col(\"payment_type\").alias(\"PaymentTypeID\"),\n",
    "    F.col(\"passenger_count\").alias(\"PassengerCount\"),\n",
    "    F.col(\"trip_distance\").alias(\"TripDistance\"),\n",
    "    F.col(\"fare_amount\").alias(\"FareAmount\"),\n",
    "    F.col(\"tip_amount\").alias(\"TipAmount\"),\n",
    "    F.col(\"tolls_amount\").alias(\"TollsAmount\"),\n",
    "    F.col(\"Airport_fee\").alias(\"AirportAmount\"),\n",
    "    F.col(\"total_amount\").alias(\"TotalAmount\"),\n",
    "    F.col(\"extra\").alias(\"Extra\"),\n",
    "    F.col(\"mta_tax\").alias(\"MTATax\"),\n",
    "    F.col(\"congestion_surcharge\").alias(\"CongestionSurcharge\")\n",
    ")\n",
    "df3.limit(5).toPandas()\n",
    "TripID\tPickupDateTimeID\tDropOffDateTimeID\tPULocationID\tDOLocationID\tRateCodeID\tPaymentTypeID\tPassengerCount\tTripDistance\tFareAmount\tTipAmount\tTollsAmount\tAirportAmount\tTotalAmount\tExtra\tMTATax\tCongestionSurcharge\n",
    "0\t0\t202410112008\t202410112014\t237\t162\t1.0\t2\t1.0\t1.11\t7.9\t0.00\t0.00\t0.00\t12.90\t1.0\t0.5\t2.5\n",
    "1\t1\t202410112025\t202410112035\t163\t236\t1.0\t1\t1.0\t1.95\t11.4\t1.64\t0.00\t0.00\t18.04\t1.0\t0.5\t2.5\n",
    "2\t2\t202410112038\t202410112050\t43\t262\t1.0\t1\t1.0\t1.56\t12.8\t3.56\t0.00\t0.00\t21.36\t1.0\t0.5\t2.5\n",
    "3\t3\t202410102056\t202410112048\t161\t158\t1.0\t1\t2.0\t2.50\t20.5\t0.00\t0.00\t0.00\t25.50\t1.0\t0.5\t2.5\n",
    "4\t4\t202410102148\t202410112053\t138\t125\t1.0\t1\t1.0\t10.59\t45.7\t6.44\t6.94\t1.75\t70.83\t6.0\t0.5\t2.5\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
