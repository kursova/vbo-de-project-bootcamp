# NYC Taxi Data Ingestion - Airflow DAG

Bu proje, NYC Taxi verilerini GitHub'dan MinIO S3'e otomatik olarak aktaran bir Apache Airflow DAG'Ä± iÃ§erir. DAG, gÃ¼nlÃ¼k olarak Ã§alÄ±ÅŸarak verileri gÃ¼venilir bir ÅŸekilde ingest eder.

## ğŸ“‹ Proje Ã–zeti

- **Kaynak**: GitHub Repository (`erkansirin78/datasets`)
- **Hedef**: MinIO S3 Bucket (bronze katmanÄ±)
- **Veri FormatÄ±**: Parquet dosyalarÄ±
- **Ã‡alÄ±ÅŸma ZamanÄ±**: Her gÃ¼n 02:00
- **Tarih MantÄ±ÄŸÄ±**: 2 gÃ¼n geriye (veri kullanÄ±labilirliÄŸi iÃ§in)

## ğŸ—ï¸ Mimari

```
GitHub Repository â†’ Airflow DAG â†’ MinIO S3
     (Kaynak)         (ETL)        (Hedef)
```

### BileÅŸenler
- **Airflow**: Workflow orchestration
- **MinIO**: S3 compatible object storage
- **Kubernetes**: Container orchestration
- **Python**: ETL mantÄ±ÄŸÄ±

## ğŸ“‚ Dizin YapÄ±sÄ±

### GitHub Kaynak YapÄ±sÄ±
```
yellow_tripdata_partitioned_by_day/
â”œâ”€â”€ year=2024/
â”‚   â”œâ”€â”€ month=5/
â”‚   â”‚   â”œâ”€â”€ day=1/
â”‚   â”‚   â”‚   â”œâ”€â”€ part-0001.parquet
â”‚   â”‚   â”‚   â””â”€â”€ part-0002.parquet
â”‚   â”‚   â”œâ”€â”€ day=2/
â”‚   â”‚   â””â”€â”€ day=3/
â”‚   â””â”€â”€ month=6/
```

### S3 Hedef YapÄ±sÄ±
```
s3://bronze/yellow_tripdata_partitioned_by_day/
â”œâ”€â”€ year=2024/
â”‚   â”œâ”€â”€ month=5/
â”‚   â”‚   â”œâ”€â”€ day=1/
â”‚   â”‚   â”‚   â”œâ”€â”€ part-0001.parquet
â”‚   â”‚   â”‚   â””â”€â”€ part-0002.parquet
â”‚   â”‚   â”œâ”€â”€ day=2/
â”‚   â”‚   â””â”€â”€ day=3/
```

## ğŸ”„ DAG Workflow

### Task Sequence
1. **get_target_date**: Hedef tarihi hesapla (execution_date - 2 gÃ¼n)
2. **check_github_data**: GitHub'da veri varlÄ±ÄŸÄ±nÄ± kontrol et
3. **check_s3_data**: S3'te veri varlÄ±ÄŸÄ±nÄ± kontrol et
4. **download_and_upload**: DosyalarÄ± indir ve S3'e yÃ¼kle
5. **log_summary**: Ä°ÅŸlem Ã¶zetini logla

### Task Dependencies
```
get_target_date â†’ [check_github_data, check_s3_data] â†’ download_and_upload â†’ log_summary
```

## âš™ï¸ KonfigÃ¼rasyon

### DAG Parametreleri
```python
- owner: 'data-team'
- start_date: datetime(2024, 5, 1)
- schedule_interval: '0 2 * * *'  # Her gÃ¼n 02:00
- max_active_runs: 1
- retries: 2
- retry_delay: 5 dakika
```

### S3/MinIO AyarlarÄ±
```python
S3_CONFIG = {
    'aws_access_key_id': 'minioadmin',
    'aws_secret_access_key': 'minioadmin123',
    'endpoint_url': 'http://minio.minio.svc.cluster.local:9000',
    'region_name': 'us-east-1'
}
```

## ğŸš€ KullanÄ±m KÄ±lavuzu

### 1. Normal Otomatik Ã‡alÄ±ÅŸma
DAG varsayÄ±lan olarak her gÃ¼n 02:00'da Ã§alÄ±ÅŸÄ±r ve 2 gÃ¼n Ã¶ncesinin verisini Ã§eker.

**Ã–rnek**: 5 MayÄ±s 2024 02:00'da Ã§alÄ±ÅŸan DAG â†’ 3 MayÄ±s 2024 verisini Ã§eker

### 2. Manual Trigger (Belirli Tarih)

#### Airflow UI Ãœzerinden:
1. Airflow Web UI'ya gidin
2. `nyc_taxi_data_ingestion_simple` DAG'Ä±nÄ± bulun
3. **"Trigger DAG"** butonuna tÄ±klayÄ±n
4. **"Logical Date"** seÃ§in (istediÄŸiniz execution date)
5. **"Trigger"** butonuna tÄ±klayÄ±n

**Ã–rnekler**:
- 20 MayÄ±s verisini Ã§ekmek iÃ§in: `execution_date = 2024-05-22`
- 15 MayÄ±s verisini Ã§ekmek iÃ§in: `execution_date = 2024-05-17`
- BugÃ¼nkÃ¼ veriyi Ã§ekmek iÃ§in: `execution_date = bugÃ¼n + 2 gÃ¼n`

#### CLI Ãœzerinden:
```bash
# Belirli bir tarih iÃ§in
kubectl exec -it airflow-scheduler-xxx -n airflow -- \
  airflow dags trigger nyc_taxi_data_ingestion_simple \
  --execution-date 2024-05-30

# Bu komut 2024-05-28 verisini Ã§ekecek
```

### 3. Backfill (Tarih AralÄ±ÄŸÄ±)

Birden fazla gÃ¼nÃ¼n verisini toplu olarak Ã§ekmek iÃ§in:

```bash
kubectl exec -it airflow-scheduler-xxx -n airflow -- \
  airflow dags backfill nyc_taxi_data_ingestion_simple \
  --start-date 2024-05-01 \
  --end-date 2024-05-31
```

## ğŸ” Monitoring ve Troubleshooting

### LoglarÄ± Kontrol Etme
```bash
# Scheduler loglarÄ±
kubectl logs -f airflow-scheduler-xxx -n airflow

# Worker loglarÄ±
kubectl logs -f airflow-worker-xxx -n airflow
```

### S3'teki Verileri Kontrol Etme
```bash
# MinIO CLI ile
mc ls minio/bronze/yellow_tripdata_partitioned_by_day/

# Specific date iÃ§in
mc ls minio/bronze/yellow_tripdata_partitioned_by_day/year=2024/month=5/day=3/
```

### Common Issues ve Ã‡Ã¶zÃ¼mleri

#### 1. GitHub API Rate Limit
**Hata**: `403 API rate limit exceeded`
**Ã‡Ã¶zÃ¼m**: DAG'Ä± daha seyrek Ã§alÄ±ÅŸtÄ±rÄ±n veya GitHub token kullanÄ±n

#### 2. S3 Connection Error
**Hata**: `Unable to connect to MinIO`
**Ã‡Ã¶zÃ¼m**: 
- MinIO servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin
- Network connectivity'yi test edin

#### 3. Missing Data
**Hata**: `No parquet files found`
**Ã‡Ã¶zÃ¼m**: 
- GitHub'da hedef tarihin verisinin mevcut olduÄŸunu kontrol edin
- Tarih formatÄ±nÄ± doÄŸrulayÄ±n

## ğŸ“Š Performans Metrikleri

### BaÅŸarÄ±lÄ± Ã‡alÄ±ÅŸma Ã–rneÄŸi (4 MayÄ±s 2024'e kadar)
- **Ä°ÅŸlenen GÃ¼nler**: 2 MayÄ±s - 4 MayÄ±s 2024
- **BaÅŸarÄ± OranÄ±**: %100
- **Ortalama Ä°ÅŸlem SÃ¼resi**: ~10-15 dakika/gÃ¼n
- **Ä°ÅŸlenen Dosya SayÄ±sÄ±**: GÃ¼n baÅŸÄ±na 20-50 parquet dosyasÄ±

### DAG Durumu KontrolÃ¼
```bash
# DAG durumu
kubectl exec -it airflow-scheduler-xxx -n airflow -- \
  airflow dags state nyc_taxi_data_ingestion_simple 2024-05-04

# Task durumlarÄ±
kubectl exec -it airflow-scheduler-xxx -n airflow -- \
  airflow tasks state nyc_taxi_data_ingestion_simple download_and_upload 2024-05-04
```

## ğŸ” GÃ¼venlik

### Credential Management
- MinIO credentials DAG iÃ§inde hardcoded (development ortamÄ± iÃ§in)
- Production iÃ§in Kubernetes secrets kullanÄ±lmasÄ± Ã¶nerilir:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: minio-credentials
data:
  access-key: <base64-encoded-key>
  secret-key: <base64-encoded-secret>
```

## ğŸš§ Gelecek GeliÅŸtirmeler

### Ã–nerilen Ä°yileÅŸtirmeler
1. **Configuration Management**: Airflow Variables/Connections kullanÄ±mÄ±
2. **Data Quality Checks**: Dosya boyutu ve format validasyonu
3. **Alerting**: Slack/Email notification ekleme
4. **Metrics**: Prometheus/Grafana integration
5. **Data Cataloging**: Metadata management ekleme

### Kod Ã–rneÄŸi - Configuration ile Flexible Date
```python
def get_target_date(**context):
    dag_run = context.get('dag_run')
    if dag_run and dag_run.conf:
        custom_date = dag_run.conf.get('target_date')
        if custom_date:
            return datetime.strptime(custom_date, '%Y-%m-%d')
    
    # Default: 2 gÃ¼n geriye
    execution_date = context['execution_date']
    return execution_date - timedelta(days=2)
```

## ğŸ“ Support

**GeliÅŸtirici**: Data Team  
**Proje**: NYC Taxi Data Ingestion  
**Version**: 1.0  
**Son GÃ¼ncelleme**: MayÄ±s 2024

### Quick Commands Cheat Sheet
```bash
# DAG durumu
airflow dags state nyc_taxi_data_ingestion_simple <date>

# Manuel trigger
airflow dags trigger nyc_taxi_data_ingestion_simple --execution-date <date>

# LoglarÄ± gÃ¶rÃ¼ntÃ¼le
airflow tasks log nyc_taxi_data_ingestion_simple <task_id> <date>

# S3 iÃ§eriÄŸi
mc ls minio/bronze/yellow_tripdata_partitioned_by_day/
```

---

**Not**: Bu DAG development ortamÄ±nda test edilmiÅŸtir. Production kullanÄ±mÄ± iÃ§in gÃ¼venlik ve monitoring iyileÅŸtirmeleri yapÄ±lmasÄ± Ã¶nerilir.